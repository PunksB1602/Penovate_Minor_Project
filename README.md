# Penovate: A Sensor-Equipped Pen for Digital Handwriting Recognition

**Penovate** is a smart pen system that captures handwriting on ordinary paper and converts it into digital text in real time.  
It integrates **motion and pressure sensors**, a **microcontroller with Bluetooth**, and a **CNNâ€“BiLSTM deep learning model** to recognize handwritten characters from sensor streams.

---

## ðŸ“Œ Background & Motivation

Digital handwriting recognition has traditionally relied on **touchscreens, graphics tablets, or optical scanning (OCR)**.  
While effective, these approaches require specialized surfaces or post-processing.  

Penovate addresses this gap by enabling **direct handwriting capture on any surface using a pen-shaped device**.  
The system combines **low-cost IMUs + pressure sensing** with a **neural sequence model**, making it portable, low-power, and extensible.

---

## ðŸ–¼ System Overview

**Architecture Workflow**:

1. **Hardware Layer**  
   - Two MPU-6050 IMUs record 6-DOF motion/orientation.  
   - An FSR detects penâ€“paper contact.  
   - Arduino Nano collects and transmits data via HC-05 Bluetooth.  

2. **Preprocessing Layer**  
   - Noise filtering (Butterworth low-pass).  
   - Stroke segmentation using pressure thresholding.  
   - Normalization & zero-padding for fixed-length input.  

3. **Recognition Layer**  
   - CNN extracts local spatial features.  
   - BiLSTM models temporal dependencies.  
   - Softmax classifier outputs characters (Aâ€“Z).  

4. **Application Layer**  
   - Real-time display of predicted characters in console or GUI.  
   - Data storage in structured datasets (JSON/CSV).  

---

## ðŸ”§ Hardware Design

- **Arduino Nano (ATmega328p)** â€“ microcontroller for acquisition  
- **MPU-6050 IMU Ã— 2** â€“ motion/orientation capture  
- **FSR sensor** â€“ pressure-based stroke detection  
- **HC-05 Bluetooth module** â€“ wireless communication  
- **Li-ion battery (7.4V, 2S)** â€“ portable power supply  

ðŸ“‚ See [`hardware/`](hardware) for:
- Schematics & wiring tables  
- AD0/IÂ²C addressing clarification (0x68 for AD0=GND, 0x69 for AD0=VCC)  
- Power design notes  

---

## ðŸ“Š Dataset & Preprocessing

- **Collection protocol**  
  - Recorded at fixed sampling rate (100 Hz)  
  - Multiple writers contributed samples for all 26 letters (Aâ€“Z)  
  - Stroke segmentation triggered by FSR pressure  

- **Preprocessing steps**  
  - Low-pass Butterworth filter for noise removal  
  - Relative motion calculation between dual IMUs  
  - Sequence normalization and zero-padding  

- **Dataset statistics**  
  - ~130 samples per character per writer  
  - Stored as JSON sequences (accelerometer, gyroscope, pressure)  

ðŸ“‚ Available in [`data/`](data).

---

## ðŸ¤– Model Architecture

- **CNN layers** â€“ extract spatial features from motion sequences  
- **BiLSTM layers** â€“ capture temporal handwriting patterns  
- **Fully Connected + Softmax** â€“ classify 26 English letters  

**Training setup**:  
- Optimizer: Adam, lr=0.001, decay every 10 epochs  
- Loss: Categorical Cross-Entropy  
- Epochs: 30  
- Batch size: 32  
- Framework: PyTorch  

ðŸ“‚ Implementation in [`models/`](models).  
ðŸ““ Jupyter notebooks in [`notebooks/`](notebooks).  

---

## ðŸ“ˆ Results

- **Character-level accuracy**: 93.2% (with batch normalization)  
- **Without batch normalization**: 78.7%  
- **Metrics reported**: Accuracy, Precision, Recall, F1-score  

**Key Observations**:  
- CNNâ€“BiLSTM significantly outperformed CNN-only and LSTM-only baselines  
- Batch normalization stabilized training and improved generalization  
- Errors mainly occurred on visually similar characters (e.g., M vs N, C vs G)  

ðŸ“‚ See [`results/`](results) for plots, training curves, and confusion matrices.

---

## ðŸ“‚ Repository Structure

